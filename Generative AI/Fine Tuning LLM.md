This page is actually dedicated towards understanding the Fine tuning of a large language model and there are couple of resources which have been used to understand this concept, all of them are mentioned below.

- [Fine Tuning LLM Crash Course By Krish Naik](https://www.youtube.com/watch?v=iOdFUJiB0Zc)

The reversal curse is like we ask gpt about something but when we ask gpt in reversed fashion we get different results, so to prevent this we need to make sure that the data is provided to the LLM from different perspectives so that it could build a good statistical representation of the data which could lead to better memorization.

![[Questions_creator.png]]

What we can do is to ask the LLM to provide rephrase of the query point which could be some statement or question/answer from different angles using different temperatures.

Talk about the hyper parameters 
- Model : Compare or analyze the performance without even using the RAG
### The need of Fine Tuning



### Techniques used for Fine Tuning 


##### LORA


