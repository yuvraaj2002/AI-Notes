{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features using VarianceThreshold:\n",
      "Index(['feature2', 'feature3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy dataset with costant, quasi-constnat feature\n",
    "dummy_data = {\n",
    "    'feature1': [0, 0, 0, 0, 0],\n",
    "    'feature2': [0, 1, 0, 1, 0],\n",
    "    'feature3': [1, 2, 3, 4, 5]\n",
    "}\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Apply VarianceThreshold\n",
    "# Here, we set the threshold to 0 to remove features with zero variance\n",
    "selector = VarianceThreshold(threshold=0)\n",
    "X_variance_threshold = selector.fit_transform(dummy_df)\n",
    "\n",
    "# Display selected features\n",
    "print(\"Selected features using VarianceThreshold:\")\n",
    "print(dummy_df.columns[selector.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      "          feature1  feature2  feature3  feature4\n",
      "feature1       1.0       1.0      -1.0       NaN\n",
      "feature2       1.0       1.0      -1.0       NaN\n",
      "feature3      -1.0      -1.0       1.0       NaN\n",
      "feature4       NaN       NaN       NaN       NaN\n",
      "Remaining features after removing correlated features:\n",
      "Index(['feature1', 'feature4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy dataset with correlated features\n",
    "correlated_data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [2, 4, 6, 8, 10],  # Perfectly correlated with feature1\n",
    "    'feature3': [5, 4, 3, 2, 1],   # Negatively correlated with feature1\n",
    "    'feature4': [1, 1, 1, 1, 1]    # Constant feature\n",
    "}\n",
    "correlated_df = pd.DataFrame(correlated_data)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlated_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Set a threshold for removing correlated features\n",
    "threshold = 0.9\n",
    "\n",
    "# Identify features to drop by going over the correlation matrix 2d grid\n",
    "columns_to_drop = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            columns_to_drop.add(colname)\n",
    "\n",
    "# Drop the correlated features\n",
    "reduced_df = correlated_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the remaining features\n",
    "print(\"Remaining features after removing correlated features:\")\n",
    "print(reduced_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information scores for each feature:\n",
      "    Feature  Mutual Information\n",
      "0  feature1            0.000000\n",
      "1  feature2            0.000000\n",
      "2  feature3            0.000000\n",
      "3  feature4            1.383333\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy dataset with features and a target variable\n",
    "dummy_data = {\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [2, 4, 6, 8, 10],\n",
    "    'feature3': [5, 4, 3, 2, 1],\n",
    "    'feature4': [1, 1, 1, 1, 1],\n",
    "    'target': [0, 1, 0, 1, 0]\n",
    "}\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Separate features and target\n",
    "X = dummy_df.drop(columns=['target'])\n",
    "y = dummy_df['target']\n",
    "\n",
    "# Calculate mutual information\n",
    "mutual_info = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a DataFrame to display the mutual information scores\n",
    "mutual_info_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mutual_info})\n",
    "\n",
    "# Display the mutual information scores\n",
    "print(\"Mutual Information scores for each feature:\")\n",
    "print(mutual_info_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tutorial_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
